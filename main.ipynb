{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: YOLOX_DATADIR=/efs/data/coco_data/\n"
     ]
    }
   ],
   "source": [
    "!export YOLOX_DATADIR=/efs/data/coco_data/\n",
    "%env YOLOX_DATADIR=/efs/data/coco_data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/efs/data/coco_data/\n"
     ]
    }
   ],
   "source": [
    "!echo $YOLOX_DATADIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"yolox-s\"\n",
    "num_accelerators = 1\n",
    "total_batch_size = 1\n",
    "num_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env_var_options = \"NEURON_RT_ASYNC_EXEC_MAX_INFLIGHT_REQUESTS=3  \" + \\\n",
    "    \"NEURON_CC_FLAGS=\\'--cache_dir=./compiler_cache --model-type=cnn-training\\' \" + \\\n",
    "    \"XLA_IR_DEBUG=1 XLA_HLO_DEBUG=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_IR_DEBUG=1\n",
      "env: XLA_HLO_DEBUG=1\n"
     ]
    }
   ],
   "source": [
    "%env XLA_IR_DEBUG=1\n",
    "%env XLA_HLO_DEBUG=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-29 13:27:01.000593:  311089  INFO ||NEURON_PARALLEL_COMPILE||: Removing existing workdir /tmp/ubuntu/parallel_compile_workdir\n",
      "usage: neuron_parallel_compile [-h]\n",
      "                               [--command {collect-and-compile,collect,clear-locks,clear-neffs,compile,clean,scan,scan-with-failed,analyze}]\n",
      "                               [--num_parallel NUM_PARALLEL]\n",
      "                               [--node_id NODE_ID] [--world_size WORLD_SIZE]\n",
      "                               [--static_schedule]\n",
      "                               [--analyze-output ANALYZE_OUTPUT]\n",
      "                               [--analyze-verbosity {1,2}]\n",
      "                               [--parallel_compile_workdir PARALLEL_COMPILE_WORKDIR]\n",
      "                               [--log_level {INFO,DEBUG,ERROR,WARNING}]\n",
      "\n",
      "neuron_parallel_compile is an utility to extract graphs from trial run of your script, perform parallel compilation of the graphs, and populate the persistent cache with compiled graphs. Your trial run should be limited to about 100 steps, enough for the utility to extract the different graphs needed for full execution.\n",
      "To avoid hang during extraction, please make sure to use xm.save instead of torch.save to save checkpoints.\n",
      "After parallel compile, the actual run of your script will be faster since the compiled graphs are already cached. There may be additional compilations due to unreached execution paths, or changes in parameters such as number of data parallel workers.\n",
      "\n",
      "Envionment Variables:\t \n",
      "    NEURON_COMPILE_CACHE_URL:\n",
      "     If not set, the default cache dir is /var/tmp/neuron-compile-cache.\n",
      "     If url starts with s3://, it will try to s3 as cache backend, and local file system otherwise.\n",
      "    NEURON_PARALLEL_COMPILE_MAX_RETRIES: By default the utility would not retry a\n",
      "     failed compilation. To retry, you can set the NEURON_PARALLEL_COMPILE_MAX_RETRIES\n",
      "     env variable to an integer value.\n",
      "\t \n",
      "    NEURON_IGNORE_TRAINING_SCRIPT_ERROR_AND_COMPILE: By default the utility will skip the compilation if\n",
      "     there is an error in training script. You can set the NEURON_IGNORE_TRAINING_SCRIPT_ERROR_AND_COMPILE\n",
      "     to continue compilation of the accumulated collected graphs.\n",
      "Cache Structure:\t \n",
      "    The cache dir would have the following structure:\n",
      "    <cache_url>/\n",
      "        neuronxcc_<neuronxcc_version>/\n",
      "                MODULE_<hlo_hash>+<flag_hash>/\n",
      "                    model.hlo_module.pb\n",
      "                    compile_flag.txt\n",
      "                    model.neff\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --command {collect-and-compile,collect,clear-locks,clear-neffs,compile,clean,scan,scan-with-failed,analyze}\n",
      "                        collect-and-compile (default): Collect traced graphs of a short run and compile on collected graphs.\n",
      "                                 Use NEURON_COMPILE_CACHE_URL in environment\n",
      "                                 or --cache_dir option in NEURON_CC_FLAGS to select cache location.\n",
      "                        collect: Run a short run (i.e. 10 steps) to collect traced graphs of training loops.\n",
      "                                 Use NEURON_COMPILE_CACHE_URL in environment to select cache location.\n",
      "                        compile: Compile on collected graphs.\n",
      "                                 Use NEURON_COMPILE_CACHE_URL in environment to select cache location.\n",
      "                        clear-locks: Clear lock files in cache. WARNING: Please ensure there are no other running compilation         tasks under same cache.\n",
      "                                 Use NEURON_COMPILE_CACHE_URL in environment to select cache location.\n",
      "                        clear-nefffs: Clear NEFF file for debug. WARNING: Please ensure there are no other running compilation         tasks under same cache.\n",
      "                                 Use NEURON_COMPILE_CACHE_URL in environment to select cache location.\n",
      "                        clean: Clean cached artifacts. WARNING: this command removes the cache dir.\n",
      "                                 Use NEURON_COMPILE_CACHE_URL in environment to select cache location.\n",
      "                        scan: Scan the cache dir to list todo/done/locked hlos. (Note failed hlos will be included in done,         use scan-with-failed otherwise) \n",
      "                                 Use NEURON_COMPILE_CACHE_URL in environment to select cache location.\n",
      "                        scan-with-failed: Scan the cache dir to list todo/done/locked/failed hlos. \n",
      "                                 Use NEURON_COMPILE_CACHE_URL in environment to select cache location.\n",
      "                        analyze: Analyze graphs to determine operator support for a short run. \n",
      "  --num_parallel NUM_PARALLEL\n",
      "                        default: 8\n",
      "  --node_id NODE_ID\n",
      "  --world_size WORLD_SIZE\n",
      "  --static_schedule     When static_schedule is on and world_size/node_id is provided, it will statically divided up the \n",
      "                        entire cache dir into task regions to be assign to each worker, if worker finishes its task regions, \n",
      "                        it will try to steal task from its neighbors. Note that it will scan the entire cache to include all \n",
      "                        hlos (todo, locked, done). So only recommended for large scale compilation with a clean cache \n",
      "                        (doesn't have much done tasks and share with tohers) \n",
      "  --analyze-output ANALYZE_OUTPUT\n",
      "                        Only supported for --command analyze. Path to location where output will be persisted.\n",
      "                        Default: cwd/model_analysis_result\n",
      "  --analyze-verbosity {1,2}\n",
      "                        Only supported for --command analyze. Level of information to be included within the output.\n",
      "                        1: add XLA operator information into the results.\n",
      "                        2: add aten metadata into results.\n",
      "                        default: 2\n",
      "  --parallel_compile_workdir PARALLEL_COMPILE_WORKDIR\n",
      "                        Folder for hlos in this compile\n",
      "  --log_level {INFO,DEBUG,ERROR,WARNING}\n"
     ]
    }
   ],
   "source": [
    "!neuron_parallel_compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "Running command: \n",
      "\n",
      "   NEURON_RT_ASYNC_EXEC_MAX_INFLIGHT_REQUESTS=3  NEURON_CC_FLAGS='--cache_dir=./compiler_cache --model-type=cnn-training' XLA_IR_DEBUG=1 XLA_HLO_DEBUG=1 torchrun --nproc_per_node=1 -m    yolox.tools.train     -n yolox-s     -d 1     -b 1     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: nvidia-smi: not found\n",
      "2024-09-17 18:41:59 | INFO     | yolox.core.trainer:197 - args: Namespace(experiment_name='yolox_s', name='yolox-s', dist_backend='nccl', dist_url=None, batch_size=1, devices=1, exp_file=None, resume=False, ckpt=None, start_epoch=None, num_machines=1, machine_rank=0, fp16=False, cache=None, occupy=False, logger='tensorboard', opts=[])\n",
      "2024-09-17 18:41:59 | INFO     | yolox.core.trainer:198 - exp value:\n",
      "╒═══════════════════╤════════════════════════════╕\n",
      "│ keys              │ values                     │\n",
      "╞═══════════════════╪════════════════════════════╡\n",
      "│ seed              │ None                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ output_dir        │ './YOLOX_outputs'          │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ print_interval    │ 10                         │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ eval_interval     │ 10                         │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ dataset           │ None                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ num_classes       │ 80                         │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ depth             │ 0.33                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ width             │ 0.5                        │\n",
      "├──────────────────��┼────────────────────────────┤\n",
      "│ act               │ 'silu'                     │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ data_num_workers  │ 4                          │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ input_size        │ (640, 640)                 │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ multiscale_range  │ 5                          │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ data_dir          │ None                       │\n",
      "├─────���─────────────┼────────────────────────────┤\n",
      "│ train_ann         │ 'instances_train2017.json' │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ val_ann           │ 'instances_val2017.json'   │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ test_ann          │ 'instances_test2017.json'  │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ mosaic_prob       │ 1.0                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ mixup_prob        │ 1.0                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ hsv_prob          │ 1.0                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ flip_prob         │ 0.5                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ degrees           │ 10.0                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ translate         │ 0.1                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ mosaic_scale      │ (0.1, 2)                   │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ enable_mixup      │ True                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ mixup_scale       │ (0.5, 1.5)                 │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ shear             │ 2.0                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ warmup_epochs     │ 5                          │\n",
      "├───────────────────┼──────────────��─────────────┤\n",
      "│ max_epoch         │ 300                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ warmup_lr         │ 0                          │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ min_lr_ratio      │ 0.05                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ basic_lr_per_img  │ 0.00015625                 │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ scheduler         │ 'yoloxwarmcos'             │\n",
      "├───────────────────┼─���──────────────────────────┤\n",
      "│ no_aug_epochs     │ 15                         │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ ema               │ True                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ weight_decay      │ 0.0005                     │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ momentum          │ 0.9                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ save_history_ckpt │ True                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ exp_name          │ 'yolox_s'                  │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ test_size         │ (640, 640)                 │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ test_conf         │ 0.01                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ nmsthre           │ 0.65                       │\n",
      "╘═══════════════════╧════════════════════════════╛\n",
      "2024-09-17 18:41:59 | INFO     | yolox.core.trainer:202 - Model Summary: Params: 8.97M, Gflops: 26.93\n",
      "2024-09-17 18:41:59 | INFO     | yolox.data.datasets.coco:63 - loading annotations into memory...\n",
      "2024-09-17 18:42:10 | INFO     | yolox.data.datasets.coco:63 - Done (t=10.68s)\n",
      "2024-09-17 18:42:10 | INFO     | pycocotools.coco:86 - creating index...\n",
      "2024-09-17 18:42:11 | INFO     | pycocotools.coco:86 - index created!\n",
      "2024-09-17 18:42:35 | INFO     | yolox.core.trainer:219 - init prefetcher, this might take one minute or less...\n",
      "2024-09-17 18:42:35 | INFO     | yolox.data.datasets.coco:63 - loading annotations into memory...\n",
      "2024-09-17 18:42:35 | INFO     | yolox.data.datasets.coco:63 - Done (t=0.27s)\n",
      "2024-09-17 18:42:35 | INFO     | pycocotools.coco:86 - creating index...\n",
      "2024-09-17 18:42:35 | INFO     | pycocotools.coco:86 - index created!\n",
      "2024-09-17 18:42:36 | INFO     | yolox.core.trainer:257 - Training start...\n",
      "2024-09-17 18:42:36 | INFO     | yolox.core.trainer:258 - \n",
      "YOLOX(\n",
      "  (backbone): YOLOPAFPN(\n",
      "    (backbone): CSPDarknet(\n",
      "      (stem): Focus(\n",
      "        (conv): BaseConv(\n",
      "          (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (dark2): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dark3): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (1): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (2): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dark4): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (1): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (2): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dark5): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): SPPBottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): ModuleList(\n",
      "            (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "            (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
      "            (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (lateral_conv0): BaseConv(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_p4): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reduce_conv1): BaseConv(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_p3): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bu_conv2): BaseConv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_n3): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bu_conv1): BaseConv(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_n4): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): YOLOXHead(\n",
      "    (cls_convs): ModuleList(\n",
      "      (0-2): 3 x Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reg_convs): ModuleList(\n",
      "      (0-2): 3 x Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cls_preds): ModuleList(\n",
      "      (0-2): 3 x Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (reg_preds): ModuleList(\n",
      "      (0-2): 3 x Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (obj_preds): ModuleList(\n",
      "      (0-2): 3 x Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (stems): ModuleList(\n",
      "      (0): BaseConv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): BaseConv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): BaseConv(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (l1_loss): L1Loss()\n",
      "    (bcewithlog_loss): BCEWithLogitsLoss()\n",
      "    (iou_loss): IOUloss()\n",
      "  )\n",
      ")\n",
      "2024-09-17 18:42:36 | INFO     | yolox.core.trainer:279 - ---> start train epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ FINISHED before_iter(), PRINTING METRICS\n",
      "\n",
      "Metric: IrValueTensorToXlaData\n",
      "  TotalSamples: 388\n",
      "  Accumulator: 019ms572.420us\n",
      "  ValueRate: 568ms975.812us / second\n",
      "  Rate: 11865.7 / second\n",
      "  Percentiles: 1%=012.331us; 5%=012.599us; 10%=012.842us; 20%=013.288us; 50%=014.317us; 80%=023.164us; 90%=074.731us; 95%=147.741us; 99%=001ms192.361us\n",
      "Metric: TensorToData\n",
      "  TotalSamples: 388\n",
      "  Accumulator: 018ms240.938us\n",
      "  ValueRate: 558ms813.545us / second\n",
      "  Rate: 11865.2 / second\n",
      "  Percentiles: 1%=011.612us; 5%=011.872us; 10%=012.109us; 20%=012.550us; 50%=013.564us; 80%=022.138us; 90%=073.572us; 95%=146.670us; 99%=001ms191.323us\n",
      "Metric: UnwrapXlaData\n",
      "  TotalSamples: 776\n",
      "  Accumulator: 041.621us\n",
      "  ValueRate: 001ms272.986us / second\n",
      "  Rate: 23734.1 / second\n",
      "  Percentiles: 1%=000.038us; 5%=000.040us; 10%=000.044us; 20%=000.045us; 50%=000.048us; 80%=000.053us; 90%=000.063us; 95%=000.093us; 99%=000.167us\n",
      "Metric: WrapXlaData\n",
      "  TotalSamples: 388\n",
      "  Accumulator: 279.602us\n",
      "  ValueRate: 009ms548.814us / second\n",
      "  Rate: 11863.1 / second\n",
      "  Percentiles: 1%=000.459us; 5%=000.490us; 10%=000.524us; 20%=000.553us; 50%=000.635us; 80%=000.811us; 90%=001.065us; 95%=001.285us; 99%=001.665us\n",
      "Counter: CreateXlaTensor\n",
      "  Value: 924\n",
      "Counter: RegisterXLAFunctions\n",
      "  Value: 1\n",
      "Counter: xla::_copy_from\n",
      "  Value: 462\n",
      "Counter: xla::_to_copy\n",
      "  Value: 462\n",
      "Counter: xla::clone\n",
      "  Value: 462\n",
      "Counter: xla::empty_symint\n",
      "  Value: 462\n",
      "Metric: OutboundData\n",
      "  TotalSamples: 388\n",
      "  Accumulator: 34.30MB\n",
      "  ValueRate: 1.02GB / second\n",
      "  Rate: 11861.5 / second\n",
      "  Percentiles: 1%=16.00B; 5%=128.00B; 10%=256.00B; 20%=256.00B; 50%=512.00B; 80%=2.00KB; 90%=256.00KB; 95%=576.00KB; 99%=2.25MB\n",
      "Metric: TransferToServerTime\n",
      "  TotalSamples: 388\n",
      "  Accumulator: 017ms259.337us\n",
      "  ValueRate: 528ms649.853us / second\n",
      "  Rate: 11861.9 / second\n",
      "  Percentiles: 1%=009.824us; 5%=009.976us; 10%=010.246us; 20%=010.503us; 50%=011.308us; 80%=017.954us; 90%=070.227us; 95%=143.412us; 99%=001ms187.640us\n",
      "Counter: CreateDataHandles\n",
      "  Value: 388\n",
      "\n",
      "TTTTTTTTT STARTING TRAIN_ONE_ITER\n",
      "\n",
      "2024-09-17 18:42:37.000097:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:42:37.000099:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/2c564ce0-b0d7-4441-b52e-2f7dbc9ccc2e/model.MODULE_5067018509817451865+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/2c564ce0-b0d7-4441-b52e-2f7dbc9ccc2e/model.MODULE_5067018509817451865+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "XXXXXXXXXXXXXXXXXXXX PRINTING labels = tensor([[[  0.0000,  15.1270, 339.5298,  30.2541, 166.7321],\n",
      "         [  0.0000, 118.4737, 267.2923,  71.3239, 189.7294],\n",
      "         [  0.0000, 253.5770, 376.5643, 169.1214, 526.8713],\n",
      "         [ 37.0000, 245.3333, 399.8252, 416.7497, 454.6733],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='xla:0')\n",
      "XXXXXXXXXXXXXXXXXXXX PRINTING labels.dtype = torch.float32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "XXXXXXXXXXXXXXXXXXXX PRINTING labels_cpu = tensor([[[  0.0000,  15.1270, 339.5298,  30.2541, 166.7321],\n",
      "         [  0.0000, 118.4737, 267.2923,  71.3239, 189.7294],\n",
      "         [  0.0000, 253.5770, 376.5643, 169.1214, 526.8713],\n",
      "         [ 37.0000, 245.3333, 399.8252, 416.7497, 454.6733],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "XXXXXXXXXXXXXXXXXXXX PRINTING labels_cpu.dtype = torch.float32\n",
      "2024-09-17 18:42:42.000074:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:42:42.000075:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/95b711a1-3a99-4980-8fba-d515181c9b9c/model.MODULE_17975828099264192223+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/95b711a1-3a99-4980-8fba-d515181c9b9c/model.MODULE_17975828099264192223+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "Step 1 - Sum along dim 2: tensor([[ 551.6429,  646.8193, 1326.1340, 1553.5815,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000]],\n",
      "       device='xla:0')\n",
      "2024-09-17 18:42:43.000601:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:42:43.000602:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/b6b00e03-f676-47c1-be16-e98b86c03edc/model.MODULE_9853358457222315288+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/b6b00e03-f676-47c1-be16-e98b86c03edc/model.MODULE_9853358457222315288+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "Step 2 - Boolean mask where sum > 0: tensor([[ True,  True,  True,  True, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='xla:0')\n",
      "2024-09-17 18:42:45.000141:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:42:45.000142:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/e2b059ca-2a06-4674-8140-a61cb444498a/model.MODULE_14952958540907189567+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/e2b059ca-2a06-4674-8140-a61cb444498a/model.MODULE_14952958540907189567+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "Step 3 - Final nlabel: tensor([4], device='xla:0')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2024-09-17 18:42:46.000702:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:42:46.000703:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/a3e3ec13-1987-4517-bb18-ffe0368a2499/model.MODULE_5127953222552620750+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/a3e3ec13-1987-4517-bb18-ffe0368a2499/model.MODULE_5127953222552620750+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "XXXXXXXXXXXXXXXXXXXX PRINTING nlabel = tensor([4], device='xla:0')\n",
      "\n",
      "\n",
      "\n",
      "XXXXXXXXXXXXXXXXXXXX PRINTING nlabel_cpu = tensor([4])\n",
      "2024-09-17 18:42:48.000275:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:42:48.000276:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/a84a095f-e8e5-422d-b1ed-eac76be7802a/model.MODULE_12773221678906379935+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/a84a095f-e8e5-422d-b1ed-eac76be7802a/model.MODULE_12773221678906379935+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "2024-09-17 18:42:49.000716:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:42:49.000717:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/6ec9f303-0b9d-4fec-841b-cac420843094/model.MODULE_12624279871136165025+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/6ec9f303-0b9d-4fec-841b-cac420843094/model.MODULE_12624279871136165025+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX gt_classes = labels[batch_idx: num_gt, 0] = (0, 4, tensor([ 0.,  0.,  0., 37.], device='xla:0'))\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX MODE: gpu\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX gt_classes device: xla:0\n",
      "2024-09-17 18:42:51.000250:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:42:51.000251:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/2e8ea389-4863-4581-a010-db984b75b42c/model.MODULE_658441038523408735+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/2e8ea389-4863-4581-a010-db984b75b42c/model.MODULE_658441038523408735+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "2024-09-17 18:42:53.000615:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:42:53.000616:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/ea60ce2e-b30f-4c4c-bd71-70e4aabeb57c/model.MODULE_8927292917880708483+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/ea60ce2e-b30f-4c4c-bd71-70e4aabeb57c/model.MODULE_8927292917880708483+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "XXXXXXXXXXXXXXXXXXXXXX Shape of fg_mask: torch.Size([8400]), sum: 88\n",
      "XXXXXXXXXXXXXXXXXXXX Shape of bboxes_preds_per_image before masking: torch.Size([8400, 4])\n",
      "\n",
      "Shape of cls_preds before masking : torch.Size([1, 8400, 80])\n",
      "Shape of obj_preds before masking : torch.Size([1, 8400, 1])\n",
      "\n",
      "AAAAAAAAAAAA LINE 462\n",
      "AAAAAAAAAAAA LINE 464\n",
      "AAAAAAAAAAAA LINE 466\n",
      "AAAAAAAAAAAA LINE 468\n",
      "\n",
      "Shape of cls_preds after masking : torch.Size([88, 80])\n",
      "Shape of obj_preds after masking : torch.Size([88, 1])\n",
      "\n",
      "XXXXXXXXXXXXXX gt_bboxes_per_image device: xla:0\n",
      "XXXXXXXXXXXXXX bboxes_preds_per_image device: xla:0\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX TL Type = torch.xla.FloatTensor\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX BR Type = torch.xla.FloatTensor\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX output_size = torch.xla.BoolTensor\n",
      "AAAAAAAAAAAA LINE 476\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXX DTYPE = torch.float32\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXX GT_CLASSES = tensor([ 0.,  0.,  0., 37.], device='xla:0')\n",
      "2024-09-17 18:42:55.000761:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:42:55.000762:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/ada7e677-3cd3-4052-9773-2af6c1456c88/model.MODULE_14469584744210157613+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/ada7e677-3cd3-4052-9773-2af6c1456c88/model.MODULE_14469584744210157613+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXX GT_CLASSES.norm() = 37.0\n",
      "2024-09-17 18:42:57.000300:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:42:57.000301:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/be239dc7-cab0-425a-b689-7ff79c90d324/model.MODULE_5244916704883203527+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/be239dc7-cab0-425a-b689-7ff79c90d324/model.MODULE_5244916704883203527+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXX Class values norm: 37.0, max: 37.0\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXX GT_CLASSES.max() = 37.0\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXX GT_CLASSES_SHAPE = torch.Size([4])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXX NUM_CLASSES = 80\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXX DTYPE = torch.float32\n",
      "2024-09-17 18:42:58.000819:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:42:58.000820:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/451dd7c0-5254-49a1-a484-007acda8d1c7/model.MODULE_9174419412051651180+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/451dd7c0-5254-49a1-a484-007acda8d1c7/model.MODULE_9174419412051651180+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "2024-09-17 18:43:00.000382:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:43:00.000383:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/12be061c-d161-44c3-afbe-72f7c8ff9fff/model.MODULE_11212839381155341668+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/12be061c-d161-44c3-afbe-72f7c8ff9fff/model.MODULE_11212839381155341668+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "2024-09-17 18:43:01.000946:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:43:01.000947:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/4f40601a-9f09-4ce6-b4ee-10f3963332fa/model.MODULE_9396722601866725341+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/4f40601a-9f09-4ce6-b4ee-10f3963332fa/model.MODULE_9396722601866725341+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "XXXXXXXXXXXXXXXXX gt_cls_per_image = tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]], device='xla:0') , SIZE = torch.Size([4, 80])\n",
      "AAAAAAAAAAAA LINE 506\n",
      "Shape of cls_preds_ before multiplication: torch.Size([88, 80])\n",
      "2024-09-17 18:43:03.000579:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:43:03.000581:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/85613ed8-f331-415a-a735-ea6847d0c75f/model.MODULE_10238174735987758826+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/85613ed8-f331-415a-a735-ea6847d0c75f/model.MODULE_10238174735987758826+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "...\n",
      "Compiler status PASS\n",
      "Sample content of cls_preds_ (first element): tensor([-5.3152, -3.6433, -3.7596, -3.9755, -7.0051, -3.6804, -6.1762, -5.3979,\n",
      "        -4.0344, -5.4944, -6.7951, -3.4169, -5.0988, -4.8887, -5.8639, -5.2567,\n",
      "        -4.9525, -5.1746, -3.2221, -4.7408, -3.8326, -3.8608, -4.1033, -3.1702,\n",
      "        -4.2587, -5.7243, -4.6039, -6.0012, -3.9456, -4.6478, -2.9999, -4.2265,\n",
      "        -5.5331, -5.3409, -6.9396, -4.6983, -4.5306, -3.7499, -5.2869, -3.6500,\n",
      "        -2.9714, -4.2233, -5.0059, -5.8081, -4.4680, -5.5100, -4.2806, -4.6255,\n",
      "        -4.7993, -3.9946, -5.4516, -4.4161, -5.4091, -4.1873, -4.0811, -3.6166,\n",
      "        -3.9208, -5.3012, -3.8054, -2.7870, -4.8903, -3.8219, -6.4833, -4.7407,\n",
      "        -4.9743, -3.6403, -3.9080, -4.4498, -5.3420, -3.3908, -5.4528, -2.6150,\n",
      "        -2.9406, -5.2917, -3.5938, -2.7058, -5.5679, -3.8412, -3.4425, -4.1496],\n",
      "       device='xla:0')\n",
      "\n",
      "Shape of obj_preds_ before multiplication: torch.Size([88, 1])\n",
      "2024-09-17 18:43:58.000151:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:43:58.000153:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/c9cedb85-ec71-43a9-a8a7-7305b9e9d59e/model.MODULE_4516448385095978619+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/c9cedb85-ec71-43a9-a8a7-7305b9e9d59e/model.MODULE_4516448385095978619+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "...\n",
      "Compiler status PASS\n",
      "Sample content of obj_preds_ (first element): tensor([-4.5281], device='xla:0')\n",
      "\n",
      "Shape of cls_preds_ after multiplication and before unsqueeze and repeat: torch.Size([88, 80])\n",
      "2024-09-17 18:44:40.000015:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:44:40.000017:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/08126cf9-20ec-41ab-a5eb-7ca83e9516ce/model.MODULE_1114553495408799599+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/08126cf9-20ec-41ab-a5eb-7ca83e9516ce/model.MODULE_1114553495408799599+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "...\n",
      "Compiler status PASS\n",
      "Sample content of cls_preds_ (first element): tensor([0.0073, 0.0169, 0.0161, 0.0144, 0.0033, 0.0166, 0.0049, 0.0071, 0.0137,\n",
      "        0.0068, 0.0036, 0.0184, 0.0083, 0.0092, 0.0056, 0.0075, 0.0088, 0.0081,\n",
      "        0.0207, 0.0098, 0.0152, 0.0149, 0.0135, 0.0210, 0.0123, 0.0061, 0.0104,\n",
      "        0.0053, 0.0146, 0.0105, 0.0226, 0.0124, 0.0067, 0.0071, 0.0033, 0.0102,\n",
      "        0.0110, 0.0160, 0.0076, 0.0167, 0.0225, 0.0126, 0.0086, 0.0059, 0.0112,\n",
      "        0.0067, 0.0125, 0.0105, 0.0094, 0.0140, 0.0069, 0.0115, 0.0073, 0.0130,\n",
      "        0.0136, 0.0169, 0.0149, 0.0073, 0.0156, 0.0253, 0.0092, 0.0155, 0.0042,\n",
      "        0.0098, 0.0089, 0.0166, 0.0146, 0.0113, 0.0073, 0.0186, 0.0071, 0.0277,\n",
      "        0.0236, 0.0073, 0.0175, 0.0257, 0.0067, 0.0152, 0.0186, 0.0129],\n",
      "       device='xla:0')\n",
      "\n",
      "Shape of gt_cls_per_image after multiplication and beforebefore unsqueeze and repeat: torch.Size([4, 80])\n",
      "2024-09-17 18:45:40.000530:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:45:40.000531:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/5d888be6-01ad-4b9f-8cdc-4862d6818b31/model.MODULE_379313110210121864+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/5d888be6-01ad-4b9f-8cdc-4862d6818b31/model.MODULE_379313110210121864+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "Sample content of gt_cls_per_image (first element): tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='xla:0')\n",
      "\n",
      "AAAAAAAAAAAA LINE 519\n",
      "AAAAAAAAAAAA LINE 527\n",
      "2024-09-17 18:45:42.000097:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:45:42.000099:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/ea0df571-a3e9-4539-aedb-51033c4b6b5c/model.MODULE_662172937020157047+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/ea0df571-a3e9-4539-aedb-51033c4b6b5c/model.MODULE_662172937020157047+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "...\n",
      "Compiler status PASS\n",
      "2024-09-17 18:46:22.000771:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:46:22.000773:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/82709851-4fd6-4025-a976-155ba17f378a/model.MODULE_12703809420932828788+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/82709851-4fd6-4025-a976-155ba17f378a/model.MODULE_12703809420932828788+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "...\n",
      "Compiler status PASS\n",
      "2024-09-17 18:47:03.000663:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:47:03.000664:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/5ff89136-47c3-489e-9b62-e61b1d316d50/model.MODULE_1209723829023391333+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/5ff89136-47c3-489e-9b62-e61b1d316d50/model.MODULE_1209723829023391333+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "...\n",
      "Compiler status PASS\n",
      "2024-09-17 18:47:45.000113:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:47:45.000115:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/83bfec96-ee21-4f39-86f9-d99fee9f83af/model.MODULE_10092587309471530189+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/83bfec96-ee21-4f39-86f9-d99fee9f83af/model.MODULE_10092587309471530189+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "...\n",
      "Compiler status PASS\n",
      "2024-09-17 18:48:26.000146:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:48:26.000148:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/94cc36c4-dce8-4c94-ac8d-76cd29791d21/model.MODULE_1856115315394075336+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/94cc36c4-dce8-4c94-ac8d-76cd29791d21/model.MODULE_1856115315394075336+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "....\n",
      "Compiler status PASS\n",
      "2024-09-17 18:49:34.000684:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:49:34.000686:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/e09c540c-c6ce-4497-be07-325a594ab2fa/model.MODULE_2894671272323470155+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/e09c540c-c6ce-4497-be07-325a594ab2fa/model.MODULE_2894671272323470155+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "....\n",
      "Compiler status PASS\n",
      "2024-09-17 18:50:42.000191:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:50:42.000192:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/3958c027-ebbb-4d36-9ebd-327254f98b19/model.MODULE_14084748520647090419+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/3958c027-ebbb-4d36-9ebd-327254f98b19/model.MODULE_14084748520647090419+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "....\n",
      "Compiler status PASS\n",
      "2024-09-17 18:51:49.000868:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:51:49.000869:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/f7671cbb-409d-4740-b32e-88b895301fec/model.MODULE_7101109372505822672+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/f7671cbb-409d-4740-b32e-88b895301fec/model.MODULE_7101109372505822672+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "....\n",
      "Compiler status PASS\n",
      "2024-09-17 18:52:58.000208:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:52:58.000210:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/b8fd8960-97e6-4d26-be3e-db5305edc6d2/model.MODULE_18213731861163517031+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/b8fd8960-97e6-4d26-be3e-db5305edc6d2/model.MODULE_18213731861163517031+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "....\n",
      "Compiler status PASS\n",
      "2024-09-17 18:54:06.000076:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:54:06.000078:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/67fd886b-6092-4e98-a676-67c940aa54d4/model.MODULE_8515962159439301634+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/67fd886b-6092-4e98-a676-67c940aa54d4/model.MODULE_8515962159439301634+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "....\n",
      "Compiler status PASS\n",
      "XXXXXXXXXXXXXXXX pred.shape = torch.Size([2, 4])\n",
      "XXXXXXXXXXXXXXXX target.shape = torch.Size([2, 4])\n",
      "2024-09-17 18:55:14.000895:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:55:14.000897:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/7802768e-9a37-495e-b4d3-cc40ab35b64c/model.MODULE_7975542431521293526+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/7802768e-9a37-495e-b4d3-cc40ab35b64c/model.MODULE_7975542431521293526+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "..\n",
      "Compiler status PASS\n",
      "XXXXXXXXXXXXXXXX pred vector = tensor([[111.3940, 260.1046,  66.5155,  38.9896],\n",
      "        [ 24.6029, 307.5402,  39.8207,  37.0953]], device='xla:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "2024-09-17 18:55:55.000484:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:55:55.000485:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/18c11641-6506-455f-8eb4-e5276d111985/model.MODULE_734118174394185813+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/18c11641-6506-455f-8eb4-e5276d111985/model.MODULE_734118174394185813+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "....\n",
      "Compiler status PASS\n",
      "XXXXXXXXXXXXXXXX target vector = tensor([[118.4737, 267.2923,  71.3239, 189.7294],\n",
      "        [ 15.1270, 339.5298,  30.2541, 166.7321]], device='xla:0')\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX FINISHED GET LOSS FUNCTION!!\n",
      "BOUTT DO SCALER.SCALE\n",
      "\n",
      "2024-09-17 18:57:04.000288:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:57:04.000289:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/b48a3733-2c4b-4c9d-94ac-73740f2ae8ae/model.MODULE_16307586817484330214+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/b48a3733-2c4b-4c9d-94ac-73740f2ae8ae/model.MODULE_16307586817484330214+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "2024-09-17 18:57:05.000735:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:57:05.000736:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/85049784-3e61-437a-a221-49d01f1bb8b5/model.MODULE_16935464418762659883+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/85049784-3e61-437a-a221-49d01f1bb8b5/model.MODULE_16935464418762659883+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "FINISHED DA SCALER\n",
      "BOUTT DO SCALER.STEP\n",
      "\n",
      "BOUTTA DO MARK STEP AFTER SCALER.UPDATE - didnt actually\n",
      "FINISHED THEEEEEE MARKSTEP FROM TRAINER.PY\n",
      "------------------------ FINISHED train_one_iter(), PRINTING METRICS\n",
      "\n",
      "Metric: DeviceLockWait\n",
      "  TotalSamples: 100\n",
      "  Accumulator: 513.934us\n",
      "  ValueRate: 000.594us / second\n",
      "  Rate: 0.115603 / second\n",
      "  Percentiles: 1%=000.566us; 5%=000.767us; 10%=000.890us; 20%=002.809us; 50%=003.477us; 80%=009.902us; 90%=010.300us; 95%=010.642us; 99%=012.073us\n",
      "Metric: InputOutputAliasCount\n",
      "  TotalSamples: 1\n",
      "  Accumulator: 388.00\n",
      "  Percentiles: 1%=388.00; 5%=388.00; 10%=388.00; 20%=388.00; 50%=388.00; 80%=388.00; 90%=388.00; 95%=388.00; 99%=388.00\n",
      "Metric: IrValueTensorToXlaData\n",
      "  TotalSamples: 410\n",
      "  Accumulator: 019ms495.339us\n",
      "  ValueRate: 021.485us / second\n",
      "  Rate: 0.451836 / second\n",
      "  Percentiles: 1%=012.352us; 5%=012.625us; 10%=012.856us; 20%=013.365us; 50%=014.510us; 80%=029.607us; 90%=072.939us; 95%=146.817us; 99%=770.239us\n",
      "Metric: TensorToData\n",
      "  TotalSamples: 430\n",
      "  Accumulator: 042ms758.871us\n",
      "  ValueRate: 046.017us / second\n",
      "  Rate: 0.473846 / second\n",
      "  Percentiles: 1%=011.647us; 5%=011.920us; 10%=012.151us; 20%=012.652us; 50%=013.831us; 80%=030.890us; 90%=071.899us; 95%=146.670us; 99%=001ms215.710us\n",
      "Metric: TensorsGraphSize\n",
      "  TotalSamples: 50\n",
      "  Accumulator: 34003.00\n",
      "  ValueRate: 39.31 / second\n",
      "  Rate: 0.0578014 / second\n",
      "  Percentiles: 1%=2.00; 5%=2.00; 10%=3.00; 20%=4.00; 50%=1046.00; 80%=1356.00; 90%=1372.00; 95%=1377.00; 99%=1379.00\n",
      "Metric: UnwrapXlaData\n",
      "  TotalSamples: 17249\n",
      "  Accumulator: 002ms362.590us\n",
      "  ValueRate: 006ms490.106us / second\n",
      "  Rate: 139423 / second\n",
      "  Percentiles: 1%=000.041us; 5%=000.041us; 10%=000.041us; 20%=000.042us; 50%=000.043us; 80%=000.048us; 90%=000.051us; 95%=000.058us; 99%=000.106us\n",
      "Metric: WrapXlaData\n",
      "  TotalSamples: 1453\n",
      "  Accumulator: 002ms841.728us\n",
      "  ValueRate: 001.766us / second\n",
      "  Rate: 1.17668 / second\n",
      "  Percentiles: 1%=000.317us; 5%=000.329us; 10%=000.339us; 20%=000.370us; 50%=000.444us; 80%=001.478us; 90%=002.253us; 95%=004.127us; 99%=008.526us\n",
      "Counter: CachedCompile\n",
      "  Value: 18\n",
      "Counter: CreateXlaTensor\n",
      "  Value: 6268\n",
      "Counter: DestroyLtcTensor\n",
      "  Value: 4821\n",
      "Counter: DestroyXlaTensor\n",
      "  Value: 4821\n",
      "Counter: DeviceDataCacheMiss\n",
      "  Value: 18\n",
      "Counter: RegisterXLAFunctions\n",
      "  Value: 1\n",
      "Counter: UncachedCompile\n",
      "  Value: 32\n",
      "Counter: xla::_copy_from\n",
      "  Value: 1750\n",
      "Counter: xla::_index_put_impl_\n",
      "  Value: 2\n",
      "Counter: xla::_to_copy\n",
      "  Value: 495\n",
      "Counter: xla::_to_cpu\n",
      "  Value: 37\n",
      "Counter: xla::add\n",
      "  Value: 1103\n",
      "Counter: xla::as_strided\n",
      "  Value: 15\n",
      "Counter: xla::binary_cross_entropy\n",
      "  Value: 1\n",
      "Counter: xla::binary_cross_entropy_with_logits\n",
      "  Value: 2\n",
      "Counter: xla::bitwise_not\n",
      "  Value: 1\n",
      "Counter: xla::cat\n",
      "  Value: 22\n",
      "Counter: xla::clamp\n",
      "  Value: 1\n",
      "Counter: xla::clamp_min\n",
      "  Value: 2\n",
      "Counter: xla::clone\n",
      "  Value: 783\n",
      "Counter: xla::convolution_backward_overrideable\n",
      "  Value: 83\n",
      "Counter: xla::convolution_overrideable\n",
      "  Value: 83\n",
      "Counter: xla::copy_\n",
      "  Value: 43\n",
      "Counter: xla::div\n",
      "  Value: 25\n",
      "Counter: xla::empty_strided_symint\n",
      "  Value: 10\n",
      "Counter: xla::empty_symint\n",
      "  Value: 603\n",
      "Counter: xla::eq\n",
      "  Value: 4\n",
      "Counter: xla::exp\n",
      "  Value: 7\n",
      "Counter: xla::expand_symint\n",
      "  Value: 3\n",
      "Counter: xla::fill_\n",
      "  Value: 7\n",
      "Counter: xla::gt\n",
      "  Value: 7\n",
      "Counter: xla::index\n",
      "  Value: 10\n",
      "Counter: xla::index_put_\n",
      "  Value: 7\n",
      "Counter: xla::log\n",
      "  Value: 3\n",
      "Counter: xla::lt\n",
      "  Value: 4\n",
      "Counter: xla::masked_fill\n",
      "  Value: 2\n",
      "Counter: xla::max\n",
      "  Value: 5\n",
      "Counter: xla::max_pool2d\n",
      "  Value: 3\n",
      "Counter: xla::maximum\n",
      "  Value: 2\n",
      "Counter: xla::min\n",
      "  Value: 3\n",
      "Counter: xla::minimum\n",
      "  Value: 2\n",
      "Counter: xla::mul\n",
      "  Value: 811\n",
      "Counter: xla::native_batch_norm\n",
      "  Value: 74\n",
      "Counter: xla::native_batch_norm_backward\n",
      "  Value: 74\n",
      "Counter: xla::neg\n",
      "  Value: 12\n",
      "Counter: xla::nonzero\n",
      "  Value: 11\n",
      "Counter: xla::norm\n",
      "  Value: 2\n",
      "Counter: xla::permute_copy\n",
      "  Value: 38\n",
      "Counter: xla::pow\n",
      "  Value: 2\n",
      "Counter: xla::prod\n",
      "  Value: 8\n",
      "Counter: xla::repeat\n",
      "  Value: 2\n",
      "Counter: xla::rsub\n",
      "  Value: 1\n",
      "Counter: xla::scatter\n",
      "  Value: 2\n",
      "Counter: xla::scatter_reduce_helper\n",
      "  Value: 2\n",
      "Counter: xla::select_copy\n",
      "  Value: 34\n",
      "Counter: xla::sigmoid\n",
      "  Value: 4\n",
      "Counter: xla::silu\n",
      "  Value: 74\n",
      "Counter: xla::silu_backward\n",
      "  Value: 74\n",
      "Counter: xla::slice_copy\n",
      "  Value: 160\n",
      "Counter: xla::sqrt\n",
      "  Value: 1\n",
      "Counter: xla::stack\n",
      "  Value: 1\n",
      "Counter: xla::sub\n",
      "  Value: 20\n",
      "Counter: xla::sum\n",
      "  Value: 19\n",
      "Counter: xla::topk\n",
      "  Value: 4\n",
      "Counter: xla::view_symint\n",
      "  Value: 69\n",
      "Counter: xla::where\n",
      "  Value: 2\n",
      "Counter: xla::zero_\n",
      "  Value: 36\n",
      "Metric: CompileTime\n",
      "  TotalSamples: 32\n",
      "  Accumulator: 14m29s929ms585.092us\n",
      "  ValueRate: 01s005ms507.536us / second\n",
      "  Rate: 0.036993 / second\n",
      "  Percentiles: 1%=01s296ms604.026us; 5%=01s440ms919.118us; 10%=01s493ms335.158us; 20%=02s528ms696.118us; 50%=05s941ms477.048us; 80%=01m07s438ms090.543us; 90%=01m08s268ms307.906us; 95%=01m09s723ms857.839us; 99%=01m09s757ms130.653us\n",
      "Metric: ExecuteTime\n",
      "  TotalSamples: 50\n",
      "  Accumulator: 040ms042.962us\n",
      "  ValueRate: 046.291us / second\n",
      "  Rate: 0.0578016 / second\n",
      "  Percentiles: 1%=078.745us; 5%=121.389us; 10%=138.555us; 20%=159.642us; 50%=304.738us; 80%=002ms843.799us; 90%=002ms937.967us; 95%=002ms977.389us; 99%=004ms895.835us\n",
      "Metric: InboundData\n",
      "  TotalSamples: 52\n",
      "  Accumulator: 81.71KB\n",
      "  ValueRate: 96.73B / second\n",
      "  Rate: 0.0601153 / second\n",
      "  Percentiles: 1%=1.00B; 5%=4.00B; 10%=4.00B; 20%=4.00B; 50%=8.00B; 80%=2.34KB; 90%=8.20KB; 95%=8.20KB; 99%=8.20KB\n",
      "Metric: OutboundData\n",
      "  TotalSamples: 430\n",
      "  Accumulator: 72.14MB\n",
      "  ValueRate: 81.41KB / second\n",
      "  Rate: 0.473846 / second\n",
      "  Percentiles: 1%=4.00B; 5%=16.00B; 10%=128.00B; 20%=256.00B; 50%=512.00B; 80%=12.50KB; 90%=256.00KB; 95%=576.00KB; 99%=2.25MB\n",
      "Metric: TransferFromServerTime\n",
      "  TotalSamples: 52\n",
      "  Accumulator: 530ms031.265us\n",
      "  ValueRate: 612.749us / second\n",
      "  Rate: 0.0601153 / second\n",
      "  Percentiles: 1%=016.289us; 5%=026.743us; 10%=077.664us; 20%=289.178us; 50%=004ms049.127us; 80%=039ms249.969us; 90%=041ms257.817us; 95%=041ms321.332us; 99%=041ms385.376us\n",
      "Metric: TransferToServerTime\n",
      "  TotalSamples: 430\n",
      "  Accumulator: 040ms349.442us\n",
      "  ValueRate: 044.464us / second\n",
      "  Rate: 0.473846 / second\n",
      "  Percentiles: 1%=009.843us; 5%=009.998us; 10%=010.277us; 20%=010.566us; 50%=011.595us; 80%=026.915us; 90%=069.428us; 95%=143.412us; 99%=001ms211.527us\n",
      "Counter: CreateCompileHandles\n",
      "  Value: 32\n",
      "Counter: CreateDataHandles\n",
      "  Value: 1441\n",
      "Counter: MarkStep\n",
      "  Value: 1\n",
      "Counter: aten::_local_scalar_dense\n",
      "  Value: 26\n",
      "Counter: aten::nonzero\n",
      "  Value: 11\n",
      "\n",
      "------------------------ FINISHED after_iter(), PRINTING METRICS\n",
      "\n",
      "Metric: DeviceLockWait\n",
      "  TotalSamples: 100\n",
      "  Accumulator: 513.934us\n",
      "  ValueRate: 000.594us / second\n",
      "  Rate: 0.115603 / second\n",
      "  Percentiles: 1%=000.566us; 5%=000.767us; 10%=000.890us; 20%=002.809us; 50%=003.477us; 80%=009.902us; 90%=010.300us; 95%=010.642us; 99%=012.073us\n",
      "Metric: InputOutputAliasCount\n",
      "  TotalSamples: 1\n",
      "  Accumulator: 388.00\n",
      "  Percentiles: 1%=388.00; 5%=388.00; 10%=388.00; 20%=388.00; 50%=388.00; 80%=388.00; 90%=388.00; 95%=388.00; 99%=388.00\n",
      "Metric: IrValueTensorToXlaData\n",
      "  TotalSamples: 410\n",
      "  Accumulator: 019ms495.339us\n",
      "  ValueRate: 021.485us / second\n",
      "  Rate: 0.451836 / second\n",
      "  Percentiles: 1%=012.352us; 5%=012.625us; 10%=012.856us; 20%=013.365us; 50%=014.510us; 80%=029.607us; 90%=072.939us; 95%=146.817us; 99%=770.239us\n",
      "Metric: TensorToData\n",
      "  TotalSamples: 430\n",
      "  Accumulator: 042ms758.871us\n",
      "  ValueRate: 046.017us / second\n",
      "  Rate: 0.473846 / second\n",
      "  Percentiles: 1%=011.647us; 5%=011.920us; 10%=012.151us; 20%=012.652us; 50%=013.831us; 80%=030.890us; 90%=071.899us; 95%=146.670us; 99%=001ms215.710us\n",
      "Metric: TensorsGraphSize\n",
      "  TotalSamples: 50\n",
      "  Accumulator: 34003.00\n",
      "  ValueRate: 39.31 / second\n",
      "  Rate: 0.0578014 / second\n",
      "  Percentiles: 1%=2.00; 5%=2.00; 10%=3.00; 20%=4.00; 50%=1046.00; 80%=1356.00; 90%=1372.00; 95%=1377.00; 99%=1379.00\n",
      "Metric: UnwrapXlaData\n",
      "  TotalSamples: 17249\n",
      "  Accumulator: 002ms362.590us\n",
      "  ValueRate: 006ms490.106us / second\n",
      "  Rate: 139423 / second\n",
      "  Percentiles: 1%=000.041us; 5%=000.041us; 10%=000.041us; 20%=000.042us; 50%=000.043us; 80%=000.048us; 90%=000.051us; 95%=000.058us; 99%=000.106us\n",
      "Metric: WrapXlaData\n",
      "  TotalSamples: 1453\n",
      "  Accumulator: 002ms841.728us\n",
      "  ValueRate: 001.766us / second\n",
      "  Rate: 1.17668 / second\n",
      "  Percentiles: 1%=000.317us; 5%=000.329us; 10%=000.339us; 20%=000.370us; 50%=000.444us; 80%=001.478us; 90%=002.253us; 95%=004.127us; 99%=008.526us\n",
      "Counter: CachedCompile\n",
      "  Value: 18\n",
      "Counter: CreateXlaTensor\n",
      "  Value: 6268\n",
      "Counter: DestroyLtcTensor\n",
      "  Value: 4821\n",
      "Counter: DestroyXlaTensor\n",
      "  Value: 4821\n",
      "Counter: DeviceDataCacheMiss\n",
      "  Value: 18\n",
      "Counter: RegisterXLAFunctions\n",
      "  Value: 1\n",
      "Counter: UncachedCompile\n",
      "  Value: 32\n",
      "Counter: xla::_copy_from\n",
      "  Value: 1750\n",
      "Counter: xla::_index_put_impl_\n",
      "  Value: 2\n",
      "Counter: xla::_to_copy\n",
      "  Value: 495\n",
      "Counter: xla::_to_cpu\n",
      "  Value: 37\n",
      "Counter: xla::add\n",
      "  Value: 1103\n",
      "Counter: xla::as_strided\n",
      "  Value: 15\n",
      "Counter: xla::binary_cross_entropy\n",
      "  Value: 1\n",
      "Counter: xla::binary_cross_entropy_with_logits\n",
      "  Value: 2\n",
      "Counter: xla::bitwise_not\n",
      "  Value: 1\n",
      "Counter: xla::cat\n",
      "  Value: 22\n",
      "Counter: xla::clamp\n",
      "  Value: 1\n",
      "Counter: xla::clamp_min\n",
      "  Value: 2\n",
      "Counter: xla::clone\n",
      "  Value: 783\n",
      "Counter: xla::convolution_backward_overrideable\n",
      "  Value: 83\n",
      "Counter: xla::convolution_overrideable\n",
      "  Value: 83\n",
      "Counter: xla::copy_\n",
      "  Value: 43\n",
      "Counter: xla::div\n",
      "  Value: 25\n",
      "Counter: xla::empty_strided_symint\n",
      "  Value: 10\n",
      "Counter: xla::empty_symint\n",
      "  Value: 603\n",
      "Counter: xla::eq\n",
      "  Value: 4\n",
      "Counter: xla::exp\n",
      "  Value: 7\n",
      "Counter: xla::expand_symint\n",
      "  Value: 3\n",
      "Counter: xla::fill_\n",
      "  Value: 7\n",
      "Counter: xla::gt\n",
      "  Value: 7\n",
      "Counter: xla::index\n",
      "  Value: 10\n",
      "Counter: xla::index_put_\n",
      "  Value: 7\n",
      "Counter: xla::log\n",
      "  Value: 3\n",
      "Counter: xla::lt\n",
      "  Value: 4\n",
      "Counter: xla::masked_fill\n",
      "  Value: 2\n",
      "Counter: xla::max\n",
      "  Value: 5\n",
      "Counter: xla::max_pool2d\n",
      "  Value: 3\n",
      "Counter: xla::maximum\n",
      "  Value: 2\n",
      "Counter: xla::min\n",
      "  Value: 3\n",
      "Counter: xla::minimum\n",
      "  Value: 2\n",
      "Counter: xla::mul\n",
      "  Value: 811\n",
      "Counter: xla::native_batch_norm\n",
      "  Value: 74\n",
      "Counter: xla::native_batch_norm_backward\n",
      "  Value: 74\n",
      "Counter: xla::neg\n",
      "  Value: 12\n",
      "Counter: xla::nonzero\n",
      "  Value: 11\n",
      "Counter: xla::norm\n",
      "  Value: 2\n",
      "Counter: xla::permute_copy\n",
      "  Value: 38\n",
      "Counter: xla::pow\n",
      "  Value: 2\n",
      "Counter: xla::prod\n",
      "  Value: 8\n",
      "Counter: xla::repeat\n",
      "  Value: 2\n",
      "Counter: xla::rsub\n",
      "  Value: 1\n",
      "Counter: xla::scatter\n",
      "  Value: 2\n",
      "Counter: xla::scatter_reduce_helper\n",
      "  Value: 2\n",
      "Counter: xla::select_copy\n",
      "  Value: 34\n",
      "Counter: xla::sigmoid\n",
      "  Value: 4\n",
      "Counter: xla::silu\n",
      "  Value: 74\n",
      "Counter: xla::silu_backward\n",
      "  Value: 74\n",
      "Counter: xla::slice_copy\n",
      "  Value: 160\n",
      "Counter: xla::sqrt\n",
      "  Value: 1\n",
      "Counter: xla::stack\n",
      "  Value: 1\n",
      "Counter: xla::sub\n",
      "  Value: 20\n",
      "Counter: xla::sum\n",
      "  Value: 19\n",
      "Counter: xla::topk\n",
      "  Value: 4\n",
      "Counter: xla::view_symint\n",
      "  Value: 69\n",
      "Counter: xla::where\n",
      "  Value: 2\n",
      "Counter: xla::zero_\n",
      "  Value: 36\n",
      "Metric: CompileTime\n",
      "  TotalSamples: 32\n",
      "  Accumulator: 14m29s929ms585.092us\n",
      "  ValueRate: 01s005ms507.536us / second\n",
      "  Rate: 0.036993 / second\n",
      "  Percentiles: 1%=01s296ms604.026us; 5%=01s440ms919.118us; 10%=01s493ms335.158us; 20%=02s528ms696.118us; 50%=05s941ms477.048us; 80%=01m07s438ms090.543us; 90%=01m08s268ms307.906us; 95%=01m09s723ms857.839us; 99%=01m09s757ms130.653us\n",
      "Metric: ExecuteTime\n",
      "  TotalSamples: 50\n",
      "  Accumulator: 040ms042.962us\n",
      "  ValueRate: 046.291us / second\n",
      "  Rate: 0.0578016 / second\n",
      "  Percentiles: 1%=078.745us; 5%=121.389us; 10%=138.555us; 20%=159.642us; 50%=304.738us; 80%=002ms843.799us; 90%=002ms937.967us; 95%=002ms977.389us; 99%=004ms895.835us\n",
      "Metric: InboundData\n",
      "  TotalSamples: 52\n",
      "  Accumulator: 81.71KB\n",
      "  ValueRate: 96.73B / second\n",
      "  Rate: 0.0601153 / second\n",
      "  Percentiles: 1%=1.00B; 5%=4.00B; 10%=4.00B; 20%=4.00B; 50%=8.00B; 80%=2.34KB; 90%=8.20KB; 95%=8.20KB; 99%=8.20KB\n",
      "Metric: OutboundData\n",
      "  TotalSamples: 430\n",
      "  Accumulator: 72.14MB\n",
      "  ValueRate: 81.41KB / second\n",
      "  Rate: 0.473846 / second\n",
      "  Percentiles: 1%=4.00B; 5%=16.00B; 10%=128.00B; 20%=256.00B; 50%=512.00B; 80%=12.50KB; 90%=256.00KB; 95%=576.00KB; 99%=2.25MB\n",
      "Metric: TransferFromServerTime\n",
      "  TotalSamples: 52\n",
      "  Accumulator: 530ms031.265us\n",
      "  ValueRate: 612.749us / second\n",
      "  Rate: 0.0601153 / second\n",
      "  Percentiles: 1%=016.289us; 5%=026.743us; 10%=077.664us; 20%=289.178us; 50%=004ms049.127us; 80%=039ms249.969us; 90%=041ms257.817us; 95%=041ms321.332us; 99%=041ms385.376us\n",
      "Metric: TransferToServerTime\n",
      "  TotalSamples: 430\n",
      "  Accumulator: 040ms349.442us\n",
      "  ValueRate: 044.464us / second\n",
      "  Rate: 0.473846 / second\n",
      "  Percentiles: 1%=009.843us; 5%=009.998us; 10%=010.277us; 20%=010.566us; 50%=011.595us; 80%=026.915us; 90%=069.428us; 95%=143.412us; 99%=001ms211.527us\n",
      "Counter: CreateCompileHandles\n",
      "  Value: 32\n",
      "Counter: CreateDataHandles\n",
      "  Value: 1441\n",
      "Counter: MarkStep\n",
      "  Value: 1\n",
      "Counter: aten::_local_scalar_dense\n",
      "  Value: 26\n",
      "Counter: aten::nonzero\n",
      "  Value: 11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 18:57:07 | INFO     | yolox.core.trainer:443 - Save weights to ./YOLOX_outputs/yolox_s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-17 18:57:08.000318:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:57:08.000322:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/d19aeedb-b09a-4eb0-85bc-6cb8467b9390/model.MODULE_1011196105946004033+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/d19aeedb-b09a-4eb0-85bc-6cb8467b9390/model.MODULE_1011196105946004033+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "......\n",
      "Compiler status PASS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 18:58:51 | INFO     | yolox.core.trainer:279 - ---> start train epoch 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ FINISHED before_iter(), PRINTING METRICS\n",
      "\n",
      "Metric: DeviceLockWait\n",
      "  TotalSamples: 104\n",
      "  Accumulator: 533.646us\n",
      "  ValueRate: 000.551us / second\n",
      "  Rate: 0.107296 / second\n",
      "  Percentiles: 1%=000.566us; 5%=000.767us; 10%=000.890us; 20%=002.780us; 50%=003.553us; 80%=009.902us; 90%=010.238us; 95%=010.594us; 99%=010.958us\n",
      "Metric: InputOutputAliasCount\n",
      "  TotalSamples: 2\n",
      "  Accumulator: 776.00\n",
      "  ValueRate: 0.89 / second\n",
      "  Rate: 0.00229838 / second\n",
      "  Percentiles: 1%=388.00; 5%=388.00; 10%=388.00; 20%=388.00; 50%=388.00; 80%=388.00; 90%=388.00; 95%=388.00; 99%=388.00\n",
      "Metric: IrValueTensorToXlaData\n",
      "  TotalSamples: 410\n",
      "  Accumulator: 019ms495.339us\n",
      "  ValueRate: 021.485us / second\n",
      "  Rate: 0.451836 / second\n",
      "  Percentiles: 1%=012.352us; 5%=012.625us; 10%=012.856us; 20%=013.365us; 50%=014.510us; 80%=029.607us; 90%=072.939us; 95%=146.817us; 99%=770.239us\n",
      "Metric: TensorToData\n",
      "  TotalSamples: 430\n",
      "  Accumulator: 042ms758.871us\n",
      "  ValueRate: 046.017us / second\n",
      "  Rate: 0.473846 / second\n",
      "  Percentiles: 1%=011.647us; 5%=011.920us; 10%=012.151us; 20%=012.652us; 50%=013.831us; 80%=030.890us; 90%=071.899us; 95%=146.670us; 99%=001ms215.710us\n",
      "Metric: TensorsGraphSize\n",
      "  TotalSamples: 51\n",
      "  Accumulator: 42400.00\n",
      "  ValueRate: 43.74 / second\n",
      "  Rate: 0.052617 / second\n",
      "  Percentiles: 1%=2.00; 5%=2.00; 10%=3.00; 20%=4.00; 50%=1046.00; 80%=1356.00; 90%=1372.00; 95%=1377.00; 99%=8397.00\n",
      "Metric: UnwrapXlaData\n",
      "  TotalSamples: 19142\n",
      "  Accumulator: 003ms579.110us\n",
      "  ValueRate: 001.568us / second\n",
      "  Rate: 9.83908 / second\n",
      "  Percentiles: 1%=000.030us; 5%=000.031us; 10%=000.032us; 20%=000.033us; 50%=000.041us; 80%=000.054us; 90%=000.127us; 95%=000.140us; 99%=000.158us\n",
      "Metric: WrapXlaData\n",
      "  TotalSamples: 1842\n",
      "  Accumulator: 002ms160.528us\n",
      "  ValueRate: 001.516us / second\n",
      "  Rate: 1.05104 / second\n",
      "  Percentiles: 1%=000.313us; 5%=000.334us; 10%=000.347us; 20%=000.393us; 50%=000.458us; 80%=001.024us; 90%=001.842us; 95%=003.340us; 99%=007.836us\n",
      "Counter: CachedCompile\n",
      "  Value: 18\n",
      "Counter: CreateXlaTensor\n",
      "  Value: 6268\n",
      "Counter: DestroyLtcTensor\n",
      "  Value: 4821\n",
      "Counter: DestroyXlaTensor\n",
      "  Value: 4821\n",
      "Counter: DeviceDataCacheMiss\n",
      "  Value: 18\n",
      "Counter: RegisterXLAFunctions\n",
      "  Value: 1\n",
      "Counter: UncachedCompile\n",
      "  Value: 33\n",
      "Counter: xla::_copy_from\n",
      "  Value: 1750\n",
      "Counter: xla::_index_put_impl_\n",
      "  Value: 2\n",
      "Counter: xla::_to_copy\n",
      "  Value: 495\n",
      "Counter: xla::_to_cpu\n",
      "  Value: 37\n",
      "Counter: xla::add\n",
      "  Value: 1103\n",
      "Counter: xla::as_strided\n",
      "  Value: 15\n",
      "Counter: xla::binary_cross_entropy\n",
      "  Value: 1\n",
      "Counter: xla::binary_cross_entropy_with_logits\n",
      "  Value: 2\n",
      "Counter: xla::bitwise_not\n",
      "  Value: 1\n",
      "Counter: xla::cat\n",
      "  Value: 22\n",
      "Counter: xla::clamp\n",
      "  Value: 1\n",
      "Counter: xla::clamp_min\n",
      "  Value: 2\n",
      "Counter: xla::clone\n",
      "  Value: 783\n",
      "Counter: xla::convolution_backward_overrideable\n",
      "  Value: 83\n",
      "Counter: xla::convolution_overrideable\n",
      "  Value: 83\n",
      "Counter: xla::copy_\n",
      "  Value: 43\n",
      "Counter: xla::div\n",
      "  Value: 25\n",
      "Counter: xla::empty_strided_symint\n",
      "  Value: 10\n",
      "Counter: xla::empty_symint\n",
      "  Value: 603\n",
      "Counter: xla::eq\n",
      "  Value: 4\n",
      "Counter: xla::exp\n",
      "  Value: 7\n",
      "Counter: xla::expand_symint\n",
      "  Value: 3\n",
      "Counter: xla::fill_\n",
      "  Value: 7\n",
      "Counter: xla::gt\n",
      "  Value: 7\n",
      "Counter: xla::index\n",
      "  Value: 10\n",
      "Counter: xla::index_put_\n",
      "  Value: 7\n",
      "Counter: xla::log\n",
      "  Value: 3\n",
      "Counter: xla::lt\n",
      "  Value: 4\n",
      "Counter: xla::masked_fill\n",
      "  Value: 2\n",
      "Counter: xla::max\n",
      "  Value: 5\n",
      "Counter: xla::max_pool2d\n",
      "  Value: 3\n",
      "Counter: xla::maximum\n",
      "  Value: 2\n",
      "Counter: xla::min\n",
      "  Value: 3\n",
      "Counter: xla::minimum\n",
      "  Value: 2\n",
      "Counter: xla::mul\n",
      "  Value: 811\n",
      "Counter: xla::native_batch_norm\n",
      "  Value: 74\n",
      "Counter: xla::native_batch_norm_backward\n",
      "  Value: 74\n",
      "Counter: xla::neg\n",
      "  Value: 12\n",
      "Counter: xla::nonzero\n",
      "  Value: 11\n",
      "Counter: xla::norm\n",
      "  Value: 2\n",
      "Counter: xla::permute_copy\n",
      "  Value: 38\n",
      "Counter: xla::pow\n",
      "  Value: 2\n",
      "Counter: xla::prod\n",
      "  Value: 8\n",
      "Counter: xla::repeat\n",
      "  Value: 2\n",
      "Counter: xla::rsub\n",
      "  Value: 1\n",
      "Counter: xla::scatter\n",
      "  Value: 2\n",
      "Counter: xla::scatter_reduce_helper\n",
      "  Value: 2\n",
      "Counter: xla::select_copy\n",
      "  Value: 34\n",
      "Counter: xla::sigmoid\n",
      "  Value: 4\n",
      "Counter: xla::silu\n",
      "  Value: 74\n",
      "Counter: xla::silu_backward\n",
      "  Value: 74\n",
      "Counter: xla::slice_copy\n",
      "  Value: 160\n",
      "Counter: xla::sqrt\n",
      "  Value: 1\n",
      "Counter: xla::stack\n",
      "  Value: 1\n",
      "Counter: xla::sub\n",
      "  Value: 20\n",
      "Counter: xla::sum\n",
      "  Value: 19\n",
      "Counter: xla::topk\n",
      "  Value: 4\n",
      "Counter: xla::view_symint\n",
      "  Value: 69\n",
      "Counter: xla::where\n",
      "  Value: 2\n",
      "Counter: xla::zero_\n",
      "  Value: 36\n",
      "Metric: CompileTime\n",
      "  TotalSamples: 33\n",
      "  Accumulator: 16m13s934ms614.959us\n",
      "  ValueRate: 01s004ms799.052us / second\n",
      "  Rate: 0.0340469 / second\n",
      "  Percentiles: 1%=01s296ms604.026us; 5%=01s440ms919.118us; 10%=01s493ms335.158us; 20%=02s528ms696.118us; 50%=05s941ms477.048us; 80%=01m08s549ms551.813us; 90%=01m08s467ms245.592us; 95%=01m09s757ms130.653us; 99%=02m44s005ms029.867us\n",
      "Metric: ExecuteTime\n",
      "  TotalSamples: 51\n",
      "  Accumulator: 043ms474.204us\n",
      "  ValueRate: 044.853us / second\n",
      "  Rate: 0.0526169 / second\n",
      "  Percentiles: 1%=078.745us; 5%=121.389us; 10%=138.555us; 20%=159.642us; 50%=304.738us; 80%=002ms843.799us; 90%=002ms937.967us; 95%=002ms093.082us; 99%=004ms895.835us\n",
      "Metric: InboundData\n",
      "  TotalSamples: 53\n",
      "  Accumulator: 34.38MB\n",
      "  ValueRate: 36.32KB / second\n",
      "  Rate: 0.0546832 / second\n",
      "  Percentiles: 1%=1.00B; 5%=4.00B; 10%=4.00B; 20%=4.00B; 50%=8.00B; 80%=2.34KB; 90%=8.20KB; 95%=8.20KB; 99%=34.30MB\n",
      "Metric: OutboundData\n",
      "  TotalSamples: 430\n",
      "  Accumulator: 72.14MB\n",
      "  ValueRate: 81.41KB / second\n",
      "  Rate: 0.473846 / second\n",
      "  Percentiles: 1%=4.00B; 5%=16.00B; 10%=128.00B; 20%=256.00B; 50%=512.00B; 80%=12.50KB; 90%=256.00KB; 95%=576.00KB; 99%=2.25MB\n",
      "Metric: TransferFromServerTime\n",
      "  TotalSamples: 53\n",
      "  Accumulator: 540ms314.256us\n",
      "  ValueRate: 557.474us / second\n",
      "  Rate: 0.0546832 / second\n",
      "  Percentiles: 1%=016.289us; 5%=026.743us; 10%=077.664us; 20%=289.178us; 50%=004ms049.127us; 80%=039ms249.969us; 90%=041ms257.817us; 95%=041ms321.332us; 99%=041ms385.376us\n",
      "Metric: TransferToServerTime\n",
      "  TotalSamples: 430\n",
      "  Accumulator: 040ms349.442us\n",
      "  ValueRate: 044.464us / second\n",
      "  Rate: 0.473846 / second\n",
      "  Percentiles: 1%=009.843us; 5%=009.998us; 10%=010.277us; 20%=010.566us; 50%=011.595us; 80%=026.915us; 90%=069.428us; 95%=143.412us; 99%=001ms211.527us\n",
      "Counter: CreateCompileHandles\n",
      "  Value: 33\n",
      "Counter: CreateDataHandles\n",
      "  Value: 1829\n",
      "Counter: MarkStep\n",
      "  Value: 1\n",
      "Counter: aten::_local_scalar_dense\n",
      "  Value: 26\n",
      "Counter: aten::nonzero\n",
      "  Value: 11\n",
      "\n",
      "TTTTTTTTT STARTING TRAIN_ONE_ITER\n",
      "\n",
      "2024-09-17 18:58:52.000763:  1722022  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-09-17 18:58:52.000766:  1722022  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/9b2b3368-9edd-4b75-8dd1-376c0291d0bc/model.MODULE_18334408780246433435+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/9b2b3368-9edd-4b75-8dd1-376c0291d0bc/model.MODULE_18334408780246433435+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      ".........root = neuronxcc/starfish/penguin/targets/transforms/TargetLowering.py\n",
      "root = neuronxcc/starfish/penguin/targets/transforms\n",
      "root = neuronxcc/starfish/penguin/targets\n",
      "root = neuronxcc/starfish/penguin\n",
      "root = neuronxcc/starfish\n",
      "\n",
      "2024-09-17 19:01:37.000199:  1722022  ERROR ||NEURON_CC_WRAPPER||: Failed compilation with ['neuronx-cc', 'compile', '--target=trn1', '--framework=XLA', '/tmp/ubuntu/neuroncc_compile_workdir/9b2b3368-9edd-4b75-8dd1-376c0291d0bc/model.MODULE_18334408780246433435+ade7b014.hlo_module.pb', '--output', '/tmp/ubuntu/neuroncc_compile_workdir/9b2b3368-9edd-4b75-8dd1-376c0291d0bc/model.MODULE_18334408780246433435+ade7b014.neff', '--model-type=cnn-training', '--verbose=35']: 2024-09-17T19:01:37Z [TEN404] Internal tensorizer error: TensorInitialization:Incorrect IR by <class 'neuronxcc.starfish.penguin.targets.transforms.TensorInitialization.TensorInitialization'> - Please open a support ticket at https://github.com/aws-neuron/aws-neuron-sdk/issues/new. You may also be able to obtain more information using the 'XLA_IR_DEBUG' and 'XLA_HLO_DEBUG' environment variables.\n",
      "\n",
      "2024-09-17 19:01:37.000199:  1722022  ERROR ||NEURON_CC_WRAPPER||: Compilation failed for /tmp/ubuntu/neuroncc_compile_workdir/9b2b3368-9edd-4b75-8dd1-376c0291d0bc/model.MODULE_18334408780246433435+ade7b014.hlo_module.pb after 0 retries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 19:01:37 | ERROR    | yolox.core.trainer:86 - Exception in training: Bad StatusOr access: INTERNAL: RunNeuronCCImpl: error condition error != 0: <class 'subprocess.CalledProcessError'>: Command '['neuronx-cc', 'compile', '--target=trn1', '--framework=XLA', '/tmp/ubuntu/neuroncc_compile_workdir/9b2b3368-9edd-4b75-8dd1-376c0291d0bc/model.MODULE_18334408780246433435+ade7b014.hlo_module.pb', '--output', '/tmp/ubuntu/neuroncc_compile_workdir/9b2b3368-9edd-4b75-8dd1-376c0291d0bc/model.MODULE_18334408780246433435+ade7b014.neff', '--model-type=cnn-training', '--verbose=35']' returned non-zero exit status 70.\n",
      "2024-09-17 19:01:37 | INFO     | yolox.core.trainer:261 - Training of experiment is done and the best AP is 0.00\n",
      "2024-09-17 19:01:37 | ERROR    | yolox.core.launch:98 - An error has been caught in function 'launch', process 'MainProcess' (1722022), thread 'MainThread' (140269788541568):\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'yolox.tools', '__loader__': <_frozen_importlib_external.SourceFileL...\n",
      "           │         └ <code object <module> at 0x7f931a810c90, file \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/tools/t...\n",
      "           └ <function _run_code at 0x7f931a99e050>\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'yolox.tools', '__loader__': <_frozen_importlib_external.SourceFileL...\n",
      "         └ <code object <module> at 0x7f931a810c90, file \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/tools/t...\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/tools/train.py\", line 138, in <module>\n",
      "    launch(\n",
      "    └ <function launch at 0x7f925a2b9240>\n",
      "\n",
      "> File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/yolox/core/launch.py\", line 98, in launch\n",
      "    main_func(*args)\n",
      "    │          └ (╒═══════════════════╤═══════════════════════════════════════════════════════════════════════════════════════════════════════...\n",
      "    └ <function main at 0x7f925a2b8e50>\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/tools/train.py\", line 118, in main\n",
      "    trainer.train()\n",
      "    │       └ <function Trainer.train at 0x7f9216b2cee0>\n",
      "    └ <yolox.core.trainer.Trainer object at 0x7f921692e800>\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/yolox/core/trainer.py\", line 84, in train\n",
      "    self.train_in_epoch()\n",
      "    │    └ <function Trainer.train_in_epoch at 0x7f921693e5f0>\n",
      "    └ <yolox.core.trainer.Trainer object at 0x7f921692e800>\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/yolox/core/trainer.py\", line 94, in train_in_epoch\n",
      "    self.train_in_iter()\n",
      "    │    └ <function Trainer.train_in_iter at 0x7f921693ef80>\n",
      "    └ <yolox.core.trainer.Trainer object at 0x7f921692e800>\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/yolox/core/trainer.py\", line 104, in train_in_iter\n",
      "    self.train_one_iter()\n",
      "    │    └ <function Trainer.train_one_iter at 0x7f921693f010>\n",
      "    └ <yolox.core.trainer.Trainer object at 0x7f921692e800>\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/yolox/core/trainer.py\", line 116, in train_one_iter\n",
      "    batch = next(iter(self.prefetcher))\n",
      "                      │    └ <torch_xla.distributed.parallel_loader.MpDeviceLoader object at 0x7f9216cb4730>\n",
      "                      └ <yolox.core.trainer.Trainer object at 0x7f921692e800>\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/aws_neuron_venv_pytorch/lib/python3.10/site-packages/torch_xla/distributed/parallel_loader.py\", line 32, in __next__\n",
      "    return self.next()\n",
      "           │    └ <function PerDeviceLoader.next at 0x7f9216d05900>\n",
      "           └ <torch_xla.distributed.parallel_loader.PerDeviceLoader object at 0x7f91703933d0>\n",
      "  File \"/home/ubuntu/aws-neuron-samples/aws_neuron_venv_pytorch/lib/python3.10/site-packages/torch_xla/distributed/parallel_loader.py\", line 44, in next\n",
      "    xm.mark_step()\n",
      "    │  └ <function mark_step at 0x7f9246b88820>\n",
      "    └ <module 'torch_xla.core.xla_model' from '/home/ubuntu/aws-neuron-samples/aws_neuron_venv_pytorch/lib/python3.10/site-packages...\n",
      "  File \"/home/ubuntu/aws-neuron-samples/aws_neuron_venv_pytorch/lib/python3.10/site-packages/torch_xla/core/xla_model.py\", line 969, in mark_step\n",
      "    torch_xla._XLAC._xla_step_marker(\n",
      "    │         │     └ <built-in method _xla_step_marker of PyCapsule object at 0x7f9256365dd0>\n",
      "    │         └ <module '_XLAC' from '/home/ubuntu/aws-neuron-samples/aws_neuron_venv_pytorch/lib/python3.10/site-packages/_XLAC.cpython-310-...\n",
      "    └ <module 'torch_xla' from '/home/ubuntu/aws-neuron-samples/aws_neuron_venv_pytorch/lib/python3.10/site-packages/torch_xla/__in...\n",
      "\n",
      "RuntimeError: Bad StatusOr access: INTERNAL: RunNeuronCCImpl: error condition error != 0: <class 'subprocess.CalledProcessError'>: Command '['neuronx-cc', 'compile', '--target=trn1', '--framework=XLA', '/tmp/ubuntu/neuroncc_compile_workdir/9b2b3368-9edd-4b75-8dd1-376c0291d0bc/model.MODULE_18334408780246433435+ade7b014.hlo_module.pb', '--output', '/tmp/ubuntu/neuroncc_compile_workdir/9b2b3368-9edd-4b75-8dd1-376c0291d0bc/model.MODULE_18334408780246433435+ade7b014.neff', '--model-type=cnn-training', '--verbose=35']' returned non-zero exit status 70.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Successful!!!\n",
      "CPU times: user 125 ms, sys: 26 ms, total: 150 ms\n",
      "Wall time: 19min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import subprocess\n",
    "print(\"Train model\")\n",
    "RUN_CMD = f\"\"\"\n",
    "   {env_var_options} torchrun --nproc_per_node={num_workers} -m \\\n",
    "   yolox.tools.train \\\n",
    "    -n {model} \\\n",
    "    -d {num_accelerators} \\\n",
    "    -b {total_batch_size} \\\n",
    "    \"\"\"\n",
    "\n",
    "print(f'Running command: \\n{RUN_CMD}')\n",
    "if subprocess.check_call(RUN_CMD,shell=True):\n",
    "   print(\"There was an error with the fine-tune command\")\n",
    "else:\n",
    "   print(\"Fine-tune Successful!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import subprocess\n",
    "print(\"Compile model\")\n",
    "COMPILE_CMD = f\"\"\"{env_var_options} neuron_parallel_compile --log_level ERROR --num_parallel 1 torchrun --nproc_per_node={num_workers} -m \\\n",
    "   yolox.tools.train \\\n",
    "    -n {model} \\\n",
    "    -d {num_accelerators} \\\n",
    "    -b {total_batch_size} \\\n",
    "    \"\"\"\n",
    "\n",
    "print(f'Running command: \\n{COMPILE_CMD}')\n",
    "if subprocess.check_call(COMPILE_CMD,shell=True):\n",
    "   print(\"There was an error with the compilation command\")\n",
    "else:\n",
    "   print(\"Compilation Success!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_xla.distributed.xla_backend\n",
    "import torch_xla\n",
    "import torch_xla.debug.metrics as met\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.utils.utils as xu\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_classes = torch.tensor([41., 50.], device='xla:0')\n",
    "gt_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_classes.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_classes.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "gt_classes = torch.tensor([ 0.,  0., 14., 56., 60.])\n",
    "num_classes = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_cls_per_image = (\n",
    "    F.one_hot((gt_classes).to(torch.int64), num_classes)\n",
    "    .float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuron_venv_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
